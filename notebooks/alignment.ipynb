{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165b0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import procrustes\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import fasttext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d2abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(path1, path2):\n",
    "    model_src = fasttext.load_model(path1)\n",
    "    model_tgt = fasttext.load_model(path2)\n",
    "    return (model_src, model_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e1abc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_word_vecs(model1, model2):\n",
    "    words1 = model1.get_words()\n",
    "    words2 = model2.get_words()\n",
    "    print(\"südafrika\" in words1)\n",
    "    print(\"südafrika\" in words2)\n",
    "    print(len(words2))\n",
    "    m1_original_vectors = np.array([model1.get_word_vector(word) for word in words1])\n",
    "    m2_original_vectors = np.array([model2.get_word_vector(word) for word in words2])\n",
    "    common = list(set(words1) & set(words2))\n",
    "    vocab_word_to_index_ = {}\n",
    "    m1_common_vec = []\n",
    "    m2_common_vec = []\n",
    "    for i in range(len(common)):\n",
    "        word = common[i]\n",
    "        vocab_word_to_index_[word] = i\n",
    "        v1 = model1.get_word_vector(word)\n",
    "        v2 = model2.get_word_vector(word)\n",
    "        v1 = v1/np.linalg.norm(v1)\n",
    "        v2 = v2/np.linalg.norm(v2)\n",
    "        m1_common_vec.append(v1)\n",
    "        m2_common_vec.append(v2)\n",
    "    \n",
    "    m1_vec = np.array(m1_common_vec)\n",
    "    m2_vec = np.array(m2_common_vec)\n",
    "\n",
    "    #fetch missing\n",
    "    missing_vocab_m1 = {}\n",
    "    missing_vocab_m2 = {}\n",
    "    for i in range(len(words1)):\n",
    "        w = words1[i]\n",
    "        if w not in common:\n",
    "            missing_vocab_m1[w] = model1.get_word_vector(w)#- m1_mean\n",
    "    for i in range(len(words2)):\n",
    "        w = words2[i]\n",
    "        if w not in common:\n",
    "            missing_vocab_m2[w] = model2.get_word_vector(w)# - m2_mean\n",
    "            \n",
    "    return (vocab_word_to_index_, m1_vec, m2_vec, missing_vocab_m1, missing_vocab_m2, m1_original_vectors, m2_original_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f53f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "6895\n",
      "(5150, 400) (5150, 400)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'südafrika'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vocab, vecs1, vecs2, missing_m1, missing_m2, point_cloud1, point_cloud2 \u001b[38;5;241m=\u001b[39m get_common_word_vecs(m1,m2)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(vecs1\u001b[38;5;241m.\u001b[39mshape, vecs2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msüdafrika\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'südafrika'"
     ]
    }
   ],
   "source": [
    "vocab, vecs1, vecs2, missing_m1, missing_m2, point_cloud1, point_cloud2 = get_common_word_vecs(m1,m2)\n",
    "print(vecs1.shape, vecs2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2a741f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedModel:\n",
    "    def __init__(self, vocab_to_index, emb):\n",
    "        self.emb = emb\n",
    "        self.vocab = vocab_to_index.copy()\n",
    "        print(\"Number of words in vocab:\",len(self.vocab))\n",
    "        self.word_count = len(self.vocab)\n",
    "        self.inverse_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.emb = self.emb / np.linalg.norm(self.emb, axis=1, keepdims=True)\n",
    "    def get_word_vector(self, word):\n",
    "        return self.emb[self.vocab[word],:]\n",
    "    def cos_similarity(self, v1, v2):\n",
    "        cos_sim = (v1 @ v2.T) / (np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "        return cos_sim\n",
    "    def compare(self, word1, word2):\n",
    "        v1 = self.get_word_vector(word1)\n",
    "        v2 = self.get_word_vector(word2)\n",
    "        return self.cos_similarity(v1,v2)\n",
    "    def get_nearest_neighbors(self, word, topn=10):\n",
    "        word_idx = self.vocab[word]\n",
    "        denominator = self.emb@(self.emb[word_idx,:])\n",
    "        similarities = denominator\n",
    "        topk = np.argsort(similarities)[-topn-1:-1][::-1]\n",
    "        for i in topk:\n",
    "            print(f\"{self.inverse_vocab[i]}: {similarities[i]}\")\n",
    "    def get_nearest_vectors(self, v, topn=10, exclude=None):\n",
    "        v_norm = np.linalg.norm(v)\n",
    "        similarities = (self.emb@v)/v_norm\n",
    "        topk = np.argsort(similarities)[::-1]\n",
    "        k = 0\n",
    "        q = 0\n",
    "        while q < topn:\n",
    "            i = topk[k]\n",
    "            if exclude == None:\n",
    "                print(f\"{self.inverse_vocab[i]}: {similarities[i]}\")\n",
    "                q+=1\n",
    "            elif i not in exclude:\n",
    "                print(f\"{self.inverse_vocab[i]}: {similarities[i]}\")\n",
    "                q+=1\n",
    "            k+=1\n",
    "                \n",
    "    def get_analogies(self, w1, w2, w3, topn=10):\n",
    "        v1 = self.get_word_vector(w1)\n",
    "        v2 = self.get_word_vector(w2)\n",
    "        v3 = self.get_word_vector(w3)\n",
    "        self.get_nearest_vectors(v1-v2+v3, topn, exclude=[self.vocab[w1], self.vocab[w2], self.vocab[w3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "874e5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE: https://fasttext.cc/docs/en/english-vectors.html, last accessed 12.08.2024, 14:11\n",
    "\n",
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    vocab = {}\n",
    "    word_vectors = []\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        vocab[tokens[0]] = len(word_vectors)\n",
    "        word_vectors.append(np.array(list(map(float, tokens[1:]))))\n",
    "    return vocab, word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "82df880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_vocab, model_1_vectors = load_vectors(\"../models/fasttext/afd_aligned.vec\")\n",
    "model_2_vocab, model_2_vectors = load_vectors(\"../models/fasttext/gruene_aligned.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd14afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 6438\n",
      "Number of words in vocab: 5437\n"
     ]
    }
   ],
   "source": [
    "a_m1 = AlignedModel(model_1_vocab, model_1_vectors)\n",
    "a_m2 = AlignedModel(model_2_vocab, model_2_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "57368828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraktion: 0.5817636921653645\n",
      "antrag: 0.47407956576005655\n",
      "fordern: 0.44713797983737236\n",
      "fdp: 0.432479833810955\n",
      "partei: 0.41127083210685245\n",
      "deshalb: 0.4111341697546953\n",
      "grüne: 0.4052617215088661\n",
      "bundestag: 0.39777133935881104\n",
      "dankherr: 0.3975764295314783\n",
      "csu: 0.3937704865961197\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_nearest_neighbors(\"afd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fdf3978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "außenpolitik: 0.4689091647115785\n",
      "außenpolitisch: 0.3710191267976566\n",
      "kommunistisch: 0.32110881006017056\n",
      "ministerin: 0.2994605379235993\n",
      "außen: 0.2942367380445296\n",
      "außenministerin: 0.2925523724773291\n",
      "frau: 0.26897802038681135\n",
      "entwicklungspolitik: 0.2588735199236723\n",
      "weiblich: 0.2540375700436837\n",
      "ahrtal: 0.23183078892176487\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_nearest_neighbors(\"feministisch\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de8d9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "südamerika: 0.3986828767570639\n",
      "afrika: 0.36700290884341097\n",
      "indonesien: 0.35343059425236933\n",
      "pakistan: 0.3173756286153637\n",
      "china: 0.2936060652138359\n",
      "indien: 0.2845339783813964\n",
      "peking: 0.23980055147073542\n",
      "südsudan: 0.22676449175820879\n",
      "sudan: 0.22517859672858548\n",
      "rücktritt: 0.22285517480691183\n",
      "entwicklungszusammenarbeit: 0.22179926412531464\n",
      "entwickeln: 0.21798652598858312\n",
      "omikron: 0.21364647025788047\n",
      "mächt: 0.20339875011985026\n",
      "erwähn: 0.20218218286446207\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_nearest_neighbors(\"südafrika\", topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96d397ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22179926412531467"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_m1.compare(\"entwicklungszusammenarbeit\", \"südafrika\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6ac651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24342163413121998"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_m1.compare(\"klima\", \"umwelt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "beb09044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macron: 0.31091448033427965\n",
      "italien: 0.27978522151493856\n",
      "franzose: 0.2550854240390471\n",
      "französisch: 0.2351356888421584\n",
      "demokrat: 0.23095543768981955\n",
      "spanien: 0.21943376109882895\n",
      "luxemburg: 0.21351960728995628\n",
      "tschechien: 0.21341944697887916\n",
      "chefin: 0.20001103990662414\n",
      "italiener: 0.19348991105975624\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_analogies(\"putin\", \"russland\", \"frankreich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "078424a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "islamisch: 0.6720314073843481\n",
      "islamist: 0.6378685565315334\n",
      "islamismus: 0.5587765477933615\n",
      "islamistisch: 0.4890151350066564\n",
      "muslim: 0.4303569514532919\n",
      "muslimisch: 0.3682572324943644\n",
      "religion: 0.32053790882665706\n",
      "religiös: 0.2917980446082167\n",
      "religionsfreiheit: 0.2701279277808758\n",
      "verfassungsfeindlich: 0.26352161033878385\n"
     ]
    }
   ],
   "source": [
    "a_m2.get_nearest_neighbors(\"islam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "856faf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_biggest_shift(m1_aligned, m2_aligned, common_vocab):\n",
    "    shifts = []\n",
    "    for word in common_vocab:\n",
    "        v1 = m1_aligned.get_word_vector(word)\n",
    "        v2 = m2_aligned.get_word_vector(word)\n",
    "        dist = np.linalg.norm(v1-v2)\n",
    "        shifts.append((word, dist))\n",
    "    sorted_by_dist = sorted(shifts, key=lambda tup: tup[1], reverse=True)\n",
    "    print(sorted_by_dist[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c0e1db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('suggerieren', 1.5235837469734292), ('enteignung', 1.5188206343923079), ('martin', 1.5181380980467045), ('haustür', 1.5163230860263281), ('ad', 1.514646546537704), ('widerstand', 1.5057987761789844), ('atmen', 1.5012036997032971), ('krone', 1.5010254989904843), ('korrekt', 1.498063182671778), ('wichtigste', 1.488169900401477), ('regelrecht', 1.487819571854431), ('inklusive', 1.485513928934004), ('reißen', 1.4849460382154651), ('gott', 1.4834750103592476), ('alternativ', 1.4828793464818693), ('beamter', 1.4818769375761878), ('faktor', 1.4816897550372639), ('dankbar', 1.481432459882718), ('theorie', 1.481261443282041), ('rücken', 1.4806454064243777), ('eröffnen', 1.4802424885805805), ('zurückziehen', 1.4799199754743557), ('ford', 1.4797530786599373), ('ausdrücken', 1.4792891326553406), ('auslösen', 1.4785842325342302), ('einigkeit', 1.4776308931255284), ('begrüß', 1.4773499293791235), ('eins', 1.477219305051788), ('geplant', 1.4770096043444105), ('gemacht', 1.4747953332205477), ('freiwillig', 1.474081975769346), ('substanz', 1.4726212210414744), ('basis', 1.4711980908836395), ('bearbeiten', 1.4710521141634096), ('team', 1.4709973130152285), ('feuer', 1.4706972598364532), ('vielfach', 1.4702842598241472), ('bemühen', 1.4700874687534171), ('einst', 1.4699163618202797), ('gerät', 1.469005748324562), ('offensive', 1.4686746394435644), ('drücken', 1.468604940231324), ('nächst', 1.468438153255286), ('new', 1.46828178922732), ('überlegung', 1.4679338355581935), ('erwähnt', 1.4678110005979632), ('sowieso', 1.4674168178889122), ('akteur', 1.4674109580984636), ('nützen', 1.466726228315421), ('erlaubnis', 1.4662975769348305), ('verzweifelt', 1.4654821155468898), ('acht', 1.4653806653116792), ('langsam', 1.4648827105318138), ('stützen', 1.4646376783573434), ('allgemein', 1.4645729453746739), ('relevant', 1.464556704397999), ('steuerung', 1.4645538973420593), ('vonseit', 1.464456547801488), ('analysieren', 1.4642563095175332), ('erschreckend', 1.4638702589286927), ('zeuge', 1.463432626842243), ('schätzen', 1.4634149121818594), ('versäumnis', 1.4633901330481238), ('ergänzen', 1.4631700564249894), ('fachleute', 1.4630946597902497), ('reserve', 1.4630784629308633), ('garantie', 1.4629482831433107), ('verfehlen', 1.4626603286799789), ('untersagen', 1.4615853969235795), ('weitem', 1.461304266639644), ('kehren', 1.460974750559324), ('ägypten', 1.46078370822607), ('vorgängerregierung', 1.460730575290023), ('autobahn', 1.4606131567398832), ('karte', 1.460486645074599), ('lauf', 1.4601093445730666), ('allenfalls', 1.4595642022424924), ('offenbaren', 1.4594414489764473), ('werk', 1.4591781698398665), ('zitat', 1.4590863449283287), ('trennen', 1.4590110832158667), ('einladung', 1.4588150957701302), ('drastisch', 1.4587280229026425), ('klingen', 1.4583198514548477), ('bewerten', 1.4582965662607335), ('nahezu', 1.4582782541719723), ('freiwilligkeit', 1.4582481217640864), ('las', 1.4582448822500857), ('konsens', 1.4581694397395872), ('post', 1.4580849870951689), ('barley', 1.4580604423590429), ('auf', 1.4579693640589286), ('rückgrat', 1.457739490237478), ('stein', 1.4572618507190767), ('festschreiben', 1.4571078955323828), ('stören', 1.4568794702812977), ('anträg', 1.4568015154422382), ('keineswegs', 1.4567356359236079), ('suche', 1.4565955110506315), ('wunsch', 1.4565244688316037)]\n"
     ]
    }
   ],
   "source": [
    "compute_biggest_shift(a_m1, a_m2, list(set(model_1_vocab.keys()) & set(model_2_vocab.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "4889466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tun: 0.3081129789352417\n",
      "bundesregierung: 0.29253244400024414\n",
      "seite: 0.28401291370391846\n",
      "sprechen: 0.27862846851348877\n",
      "wirtschaftlich: 0.2744219899177551\n",
      "der: 0.2739515006542206\n",
      "sollen: 0.2710886001586914\n",
      "geben: 0.27041247487068176\n",
      "politisch: 0.2701123356819153\n",
      "frau: 0.2672087550163269\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_nearest_neighbors(\"erfolg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "9c09d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neu: 0.2567260265350342\n",
      "groß: 0.23197662830352783\n",
      "jahr: 0.2203635722398758\n",
      "besonderer: 0.2193661630153656\n",
      "letzter: 0.2162303626537323\n",
      "stehen: 0.21001777052879333\n",
      "erreichen: 0.20685796439647675\n",
      "sehen: 0.20183128118515015\n",
      "ganz: 0.2011057436466217\n",
      "darauf: 0.19987910985946655\n"
     ]
    }
   ],
   "source": [
    "a_m2.get_nearest_neighbors(\"erfolg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "caef4875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irrsinnig: 0.5054561692888472\n",
      "welch: 0.22729446882487508\n",
      "windindustrieanlag: 0.2134466379973569\n",
      "vernichten: 0.20540815538084337\n",
      "welcher: 0.20159260125297307\n",
      "wahnsinn: 0.20051785546261558\n",
      "kohleausstieg: 0.1969076098693952\n",
      "energiepolitik: 0.19562326384339365\n",
      "schädig: 0.19514797618465315\n",
      "grün: 0.19347625696535914\n",
      "irr: 0.36627251803178107\n",
      "tagebau: 0.26502418882226064\n",
      "unsinn: 0.2354000918803872\n",
      "atomwaffe: 0.2347204401509786\n",
      "windkraftanlage: 0.22886239946166592\n",
      "mitwirken: 0.22839863974371388\n",
      "neubau: 0.22155908948324157\n",
      "irre: 0.22100863644437257\n",
      "windkraft: 0.2200186408827055\n",
      "zerstörung: 0.21694000969569632\n"
     ]
    }
   ],
   "source": [
    "a_m1.get_nearest_neighbors(\"irrsinn\")\n",
    "a_m2.get_nearest_neighbors(\"irrsinn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d6a97632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 5437\n",
      "range(4456, 6438)\n",
      "(5437, 300)\n"
     ]
    }
   ],
   "source": [
    "test2 = AlignedModel(vocab_full_2, vecs2, zero_range_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "6c9fb9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halle: 0.5601162910461426\n",
      "lübcke: 0.4330243468284607\n",
      "anschlag: 0.4186391234397888\n",
      "breitscheidplatz: 0.3907088339328766\n",
      "nsu: 0.3698315918445587\n",
      "rassistisch: 0.3676041066646576\n",
      "opfer: 0.3576444685459137\n",
      "walter: 0.35632702708244324\n",
      "mord: 0.3559960722923279\n",
      "synagoge: 0.3415311574935913\n"
     ]
    }
   ],
   "source": [
    "test2.get_nearest_neighbors(\"hanau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e06c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
